import { NextRequest, NextResponse } from 'next/server';
import { withCreditGuard } from '@/lib/withCreditGuard';
import { estimateChatUsdMicros } from '@/lib/pricing';

const QUALITY_MODEL_MAP: Record<string, string> = {
  'nano': 'gpt-5-nano',
  'mini': 'gpt-5-mini',
  'high': 'gpt-5',
};

export const POST = withCreditGuard<{ quality?: string; companyName?: string; companyType?: string; product?: string; thread?: string; orientation?: string; duration?: string }>({
  estimateUsdMicros: async ({ quality = 'mini' }) => {
    const model = QUALITY_MODEL_MAP[quality] || QUALITY_MODEL_MAP['mini'];
    // Conservative estimate with buffer for reasoning tokens
    return estimateChatUsdMicros(model, 2000, 3500);  // Increased buffer
  },
  runWithUsageUsdMicros: async ({ companyName, companyType, product, thread, quality = 'mini', orientation = 'horizontal', duration = '12' }, _req, _context) => {

    if (!companyName || !companyType || !thread) {
      const res = NextResponse.json(
        { error: 'Company name, type, and thread are required' },
        { status: 400 }
      );
      return { response: res, usageUsdMicros: 0 };
    }

    // Get the model based on quality level
    const model = QUALITY_MODEL_MAP[quality] || QUALITY_MODEL_MAP['mini'];
    
    // Determine video dimensions based on orientation
    const videoDimensions = orientation === 'vertical' ? '720x1280 (Portrait)' : '1280x720 (Landscape)';
    const frameComposition = orientation === 'vertical' 
      ? 'Vertical/portrait framing with subjects centered. Optimize for mobile viewing with close-up shots and minimal horizontal movement.'
      : 'Horizontal/landscape framing with wider shots. Utilize full width for cinematic compositions and dynamic camera movements.';

    console.log('Generating script for:', { companyName, companyType, product, thread, quality, model, orientation, duration });

    const prompt = `You are a professional video advertisement scriptwriter. Create a detailed ${duration}-second video ad script optimized for ${orientation} video format.

Company: ${companyName}
Type: ${companyType}${product ? `\nProduct Details: ${product}` : ''}
Creative Thread: ${thread}
Video Format: ${videoDimensions}
Frame Composition: ${frameComposition}
Duration: ${duration} seconds

Create a ${duration}-second video ad script with:
- 3 distinct scenes (approximately 3-5 seconds each)
- Specific timing for each scene
- Detailed visual descriptions optimized for ${orientation} framing
- Voice-over (VO) text
- Optional on-screen text for the final scene

IMPORTANT: All visual descriptions should be optimized for ${videoDimensions} format with ${frameComposition.toLowerCase()}

Format the script EXACTLY like this example (adjust scene timings for ${duration} seconds):

${duration}-Second Video Ad Script

Scene 1 — [0-${Math.floor(parseInt(duration) / 3)}s | Opening hook]
(Visual: Describe the opening visual in detail)
VO: "Voice-over text here"

Scene 2 — [${Math.floor(parseInt(duration) / 3)}-${Math.floor(parseInt(duration) * 2 / 3)}s | Product introduction/transformation]
(Visual: Describe the main visual)
VO: "Voice-over text here"

Scene 3 — [${Math.floor(parseInt(duration) * 2 / 3)}-${duration}s | Resolution & brand message]
(Visual: Describe the closing visual)
VO: "Voice-over text here"
On-screen text: Brand tagline

Make it emotional, impactful, and suitable for Sora video generation. Focus on visuals that can be generated by AI.
Remember: This is for ${videoDimensions} ${orientation} video format - compose all scenes accordingly.`;

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.OPEN_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
      model: model,
      messages: [
        {
          role: 'system',
          content: 'You are a professional video advertisement scriptwriter with expertise in short-form content.'
        },
        {
          role: 'user',
          content: prompt
        }
      ],
    }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      const res = NextResponse.json({ error: errorData.error?.message || 'Failed to generate script', details: errorData }, { status: response.status });
      return { response: res, usageUsdMicros: 0 };
    }

    const data = await response.json();
    const script = data.choices[0].message.content;

    console.log('Generated script:', script);

    const res = NextResponse.json({ success: true, script });
    const usage = data.usage;
    const inputTokens = usage?.prompt_tokens ?? 1000;
    const outputTokens = usage?.completion_tokens ?? 1500;
    const usageUsdMicros = estimateChatUsdMicros(model, inputTokens, outputTokens);
    return { response: res, usageUsdMicros };
  }
});

